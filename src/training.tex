
In order to address the communication barrier and to speak the same language, the HEP community should be trained in ML concepts and terminology as part of a standard curriculum. The training should focus on well-maintained and well-documented software packages. It should provide lectures on general ML concepts and hands-on tutorials on specific tools based on concrete examples.

Being able to apply machine learning to practical HEP problems requires the understanding of basic ML concepts and algorithms. For this, regular data science lecture series and seminars, like~\cite{mlhep}, are very useful. At the university level, courses dedicated to machine learning applications in physics research is an excellent way to train undergraduate and graduate students. For example, the ``Deep Learning in Physics Research'' course with 60 participants consisting of 12 lectures and exercises which are performed on 20 GPUs of the VISPA internet platform~\cite{vispa}. %Such resources should be made more centrally available.

Experiments currently have training activities for newcomers that focus on analysis software and introduction to domain knowledge~\cite{2016chep.confE.334B}. Machine learning should next be incorporated into the incoming collaborators training efforts of the experiments.

As discussed in the training chapter, ensuring the development and availability of resources for knowledge transfer is likewise essential to ML. %The following resources are useful


%---------------------------------------------------------------
% THE TRAINING SECTION HAS MOVED:
%  https://www.sharelatex.com/project/595500273c5204ff35dfdcf9
%--------------------------------------------------------------



\begin{comment}
% ---------------------------------------------------
% CHAPTER SUMMARY MESSAGE: Motivate the need for training in the HEP community,
%  summarize existing training efforts to motivate that we already spend funding on
% this. Discuss initiatives and programs which can be developed in the coming years
% including a discussion of the known training needs of the community.

% ---------------------------------------------------

%Contributors: Fernanda Psihas, Justin Vasel, Michela Paganini, Douglas Davis, Savannah Thais, Martin Vala, Jonas Eschle, Xavier Vilas√≠s-Cardona, Jamal Rorie, Sean-Jiun Wang, Liz Sexton-Kennedy, Sergei Gleyzer, Laurent Basara, Kurt Rinnert, Bob Stienen, Matt Bellis, Meghan Kane (Industry - SoundCloud), Dario Menasce, Pat Skubic


Throughout the last few decades the field of HEP has consistently either driven or utilized the latest innovations in computational tools and technologies for problem solving.
The tool-set of the particle physicist is vast and ever-growing, and the problem set increasingly complex.
A typical graduate student or postdoc working on HEP experiments will likely encounter a number of tools, software and/or programming languages which they are totally unfamiliar with.
This requires "on-the-job" training for the same people whose work drives the reach of our analyses in parallel as they develop the tools that will be implemented for them.


*Note: Meghan wrote the paragraph below from a perspective that is outside HEP, so it needs proofreading. Where does it fit in the training section? It also needs help with providing relevant examples to HEP. The Python and Root references should be checked (i just thought of them off the top of my head), and other/more relevant examples can be swapped out.

It is important for the broad HEP community to invest in training physicists in the essential software skills to produce the best possible science. Additionally, software engineering skills exist on many different levels. The level of depth of software engineering skills that a physicist should be trained in may vary depending on the problems that face the particular physicist. Determining the level of depth necessary may evolve over time according to the problem at hand. For example, it may be sufficient to be only familiar with Python and data analysis libraries to perform basic data analysis. However, the skills required for (insert example: contributing to a large open source project, such as Root) require a higher order of thinking with respect to software development. Higher order skills may include, but are not limited to, an understanding of writing testable code, time and space complexity implications, and an understanding of common software architecture paradigms.


\textcolor{pink}{Re-read next paragraph:}
Any good research community will consist of independent actors who can question and direct their own analysis, rather than automatons who blindly follow prescriptions and recipes.
Machine learning (ML) has become an integral part of HEP analyses, at many stages of the detector hits $\rightarrow$ inference pipeline, even though it can be extremely challenging to learn, let alone master.
It is therefore imperative, that the community be proactive about providing training resources and opportunities for the good of the analyses, but also so that we follow through on our promises that HEP can \textcolor{red}{SEND PEOPLE TO INDUSTRY WHO ARE CAPABLE OF CONTRIBUTING RIGHT AWAY (THISNEEDSTOBEREWRITTEN); suggest that the emphasis here should be that we need to provide career paths for HEP people who leave the field due to limited opportunities for advancement within HEP}.

\subsection{Motivation}

With the introduction of increasingly complex tools, such as machine learning algorithms, in multiple areas of HEP, as detailed in~\ref{sec:ml_tools}, we have driven increasing improvements in the performance of our analyses and reach overall.
It is the analyzers, however, who drive these advancements through novel implementations of the technology. Thus, the development of new tools is insufficient to drive advancements in the field without researchers with the expertise to apply them to physics questions. Furthermore, a larger, better connected community with expertise in the tools and access to new developments can emulate the success of the open-source model within the large community of HEP. The efforts to train the community in all relevant tools is, thus, a priority within the R\&D effort in itself.


However, as tools become more complex the learning rate of developers must keep up with newly developed techniques if we are to utilize them effectively.
Simultaneously, as in every branch of research, it is imperative to preserve efforts to maintain reproducibility, which requires expertise on previously used tools to be maintained.





\begin{itemize}
 \item Lack of resources stalls progress
 \item Understanding the underlying algorithms makes applications more efficient, enables people to choose the right tool for a given application
 \item Rapidly changing field
 \item Efforts get duplicated in the community, this delays the learning curve to implementation time
 \item Transferrable skills (related to bridges to other communities)
 \item Unifying efforts with bridging to the community + training can help find ML experts to help with HEP implementation of ML Can we do some research into the motivations and advantages of existing training efforts? (From different experiments and from industry)\end{itemize}

Beyond the immediate benefit to the scientific community in having well-trained collaborators, there is the fact that most people who start a physics graduate program will have careers outside of academia. This is reflected in several calls for proposals from the NSF (National Science Foundation) that incentivize training in computer infrastructure and information areas.

\begin{quote}
 \emph{The overarching goal of this program is to prepare, nurture and grow the national scientific workforce for creating, utilizing, and supporting advanced cyberinfrastructure (CI) that enables cutting-edge science and engineering and contributes to the Nation's overall economic competiveness and security.}

 {\bf - Training-based Workforce Development for Advanced Cyberinfrastructure (CyberTraining) Webinar}\footnote{ \url{https://www.nsf.gov/events/event_summ.jsp?cntn_id=190179&org=NSF}}
\end{quote}


\begin{quote}
 \emph{New information, communication, and computational technologies have had profound impacts on the practice of science (in this solicitation, the term science includes the natural, mathematical, computing, and social sciences),  engineering, and education. This includes the means by which citizens of all ages use science  and engineering to enhance professional and private lives.  The systems, tools, and services emerging from these new technologies are linked to create a comprehensive cyberinfrastructure that is enabling individuals, groups, and organizations to advance research and education in ways that revolutionize who can participate, what they can do, and how they do it. Sustaining this revolution across all areas of science, engineering, and education requires the formation of a citizenry and workforce with the knowledge and skills needed to design and deploy as well as adopt and apply these cyber-based systems, tools and services over the long-term. The opportunity for such preparation should be available at all stages of formal and informal education (K-16 and lifelong), training and professional development, and must be extended to all individuals and communities.}

 {\bf - Cyberinfrastructure Training, Education, Advancement, and Mentoring for Our 21st Century Workforce (CI-TEAM)}\footnote{ \url{https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=12782}}
\end{quote}



\subsection{Training needs of the community}

The HEP user community consists of a diverse set of users; in experience level, interests, and available time to learn new techniques.
If we view the entire community as virtually enrolling in a community-wide course in ML, an undergraduate doing a summer research project has different needs and abilities than their mentoring professor.
Any sort of training program must take into account these target audiences.
For purposes of training, it is useful to think of all our user community as \emph{students}.
To be more specific, we identify three broad sets of students, classified by experience level, recognizing that even within these groups there will be people who will learn at different speeds and with differening depths of understanding.


\begin{description}
\item[Beginners] - New collaborators with no knowledge of the tools or techniques. These might be undergrads but they could also be senior researchers who have not yet engaged in any ML analysis.
\item[Intermediate users] - HEP analyzers with some experience in either ML concepts and/or tools, but are looking to supplement their experiences.
\item[Advanced users] - HEP ML experts who have mastered current (at that point in time) concepts and implementations and want to stay up-to-date with new developments.
\end{itemize}

\emph{Where appropriate}, any training program should take advantage of developments in pedagogy, such as active learning\footnote{\url{http://www.crlt.umich.edu/tstrategies/tsal}} or peer learning\footnote{\url{https://en.wikipedia.org/wiki/Peer_learning}}. In some cases, it may even be advantageous to have code samples that are purposely broken or flawed, and ask students to fix or improve them. Learning the material in such a way that it sticks with the students is difficult and is a challenge for both the students and the instructor and often takes more time than we would prefer. However, it is the best way to ensure an educated community that can fully contribute to the physics analysis tasks at hand, which is really the ultimate goal of any training program.
\medskip

A difficulty that has emerged in the past with respect to implementation of training courses is the lack of funding along with the lack of devoted time by experts in the field. People with enough expertise or insight in the field have usually no time to dedicate to prolonged periods of student's training, and, even when they can find some, the cost of setting up a training course in an effective way is beyond what's made available by Funding Agencies. A possible way out is a completely different approach to training (but complementary to the already existing and successful efforts such as the CERN School of Computing, the Bertinoro and Kit ones): instead of direct teaching to students, trainees could make use of a web-based platform to provide training materials to students. This approach has several advantages over traditional approaches:
\begin{itemize}
 \item the tutor can add material to the web site at a very slow pace (whenever they find time to do it, one slide a week or a chapter a day)
 \item his material can be further expanded by collaborators (also at their own pace) or, even better and more productively, by students who decide to contribute with examples, exercises etc. Such a collaborative effort allows more people to be exposed to training at any given time, creates a sense of community and creates bridges between people in contiguous areas or research. Students can use that same platform to exchange their own examples, make suggestions, point out interesting concepts etc...
 \item if complemented by the availability of remote virtual machines (possibily through a browser), students could have access to examples and exercises that are already embedded in their own natural environment: all the necessary tools/libraries needed to implement the exercise will be already available in the virtual machine (possibily a Docker container). With just a web-browser, students could run complex examples from home, taking advantage of a remote facility that provides some storage and computing power.
 \item there would no longer be a need to find the resources to host a school and pay the tutor(s) (and eventually subsidize the students to participate the training in a remote location). Students can follow the training at their own pace from wherever they happen to be: a traditional school only lasts for 5 days (10 at most) and it is difficult to cover a  subject to any significant depth in such a short time. The web approach, instead, allows for very long and in-depth coverage of any kind of subject, and in this sense it could be a \emph{complementary} approach to a traditional school. Of particular interest could be courses such as, e.g., "Machine Learning", "Statistical Analyis with ROOT", or even just "Good practices in C++ or Python Programming for scientific computing"
\end{itemize}

Such a web-based platform already exists, and has been realized as an Open Source project (backed by Wikimedia) by a group of italian students (the group of developers is already above 30 people). The project is WikiToLearn (\url{https://it.wikitolearn.org/}). It hosts training material in several languages, for several disciplines, ranging from Economy, to Physics, Mathematics and several others. Being based upon wikimedia software, it is very easy to add material to the site, make it appear under a specific topic (such as, e.g., Software/Techniques/Machine-Learning) and manipulate it as if it would be a single document. In the end, students can selectively choose individual chapters from the site and have the corresponding pdf sent them as a book, complete with index, content and chapters.

The adoption of such an approach is made rather easy in WikiToLearn by the relative simplicity of the wikimedia-based toolset: users contribute their training material using just a web-browser, and in order to do this efficiently the learning curve has been kept appropriately shallow.


\item given the competition for permanent positions, physicist leave HEP for industry and have to learn new tools. Using common tools will avoid an additional learning curve.



\subsection{Knowledge that needs to be transferred}

At all stages of ML training, we should take care to encourage Good Practices Across the Community (GPAC), i.e. error checking, modularity of code design, etc. This is a concept that should not be specific to ML training, but should be incorporated at every level of computational training. Having said that, in this section , we discuss ML-specific concepts that need to be taught to users of these tools. \textcolor{red}{DO WE WANT TO SPECIFIY WHETHER OR NOT THESE ARE TAUGHT TO BEGINNERS OR INTERMEDIATE FOLKS?}
\begin{itemize}
 \item Existing case studies beyond conference presentations
 \item Knowledge of algorithms
 \item Existing frameworks (most used)
 \item Evaluation metrics
 \item ‚ÄúTrust‚Äù metrics (data driven tests, etc)
 \item Various tools and their advantages in specific types of problems
 \item Specific software implementation training
 \item Good practices (preventing overfitting, etc.)
 \item Scripting / cleaning data
 \item Reporting results reproducibly
\end{itemize}

\subsection{Implementation}
The implementation of training should target multiple training formats and knowledge transfer: such as videos, twikis, lectures, jupyter notebooks and advanced visualizations, etc.
People who learn in non-conventional ways should not be excluded from the opportunity of learning about ML. Since there are different stages of knowledge transfer, programs should be developed that encourage experts to share knowledge.
In this regard, there has been an effort started in the \href{https://iml.web.cern.ch/}{Inter-Experimental LHC Machine Learning Working Group} (IML) to create a community curated GitHub repository of machine learning related work and resources for high energy physics called ``\href{https://github.com/iml-wg/HEP-ML-Resources}{\textcolor{blue}{HEPML Resources}}''. Issues considered in this section include global training initiatives, strategies for leveraging existing forums, establishing links to the general ML community, and training tool development.

\subsubsection{Community Global Training}

Initiatives that have been considered  to implement global training include:

\begin{itemize}
 \item Massive Online Open Courses can be used to develop an open-source set of tutorials and tools. Existing online courses (e.g. a best of Udacity\&Coursera) can be evaluated and recommended to the community.
 \item Experiment specific and global knowledge bases can be established with incentives for experts to contribute.
 \item Question-and-answer web sites such as HEP ML Stack Overflow
       %(https://en.wikipedia.org/wiki/Stack_Overflow)
       / Stack Exchange are very useful.
       %(https://en.wikipedia.org/wiki/Stack_Exchange)
 \item An ML expert/tutor volunteer network (office hours style) can be established.
 \item Investing in periodic in-person, hands-on workshops cn be continued.
\end{itemize}

\subsubsection{Leveraging existing forums}

To achieve our goals for training the community in ML, we can take advantage of existing training forums. Resources such as conferences, workshops, and schools (in person and online) can provide a lot of value for our training purposes while requiring little effort to set up. We should leverage these existing training forums that are already developed that most closely match the HEP community's needs.

Several industry conferences already exist that bring together those in academia and industry who are at the cutting edge of these techniques. Conferences such as NIPS\footnote{\url{https://nips.cc}} and PyData\footnote{\url{https://pydata.org}} provide a focused place where attendees can learn a lot about ML in a short period of time. ML concepts such as current ML methods, tools, and problems facing industry and academia can be learned at conferences. In addition, conferences are an excellent networking opportunity; attendees can meet and share ideas with fellow ML learners and experts. Bonds can be formed quickly at conferences that can be maintained after the duration of the conference. These connections to the outside community can be essential since we will be evolving training materials to ensure that they stay relevant over time.


Within the HEP community, we already have some working examples of dedicated training environments that alternate between general topics and experiment-specific topics. The LHC Physics Center (LPC) at Fermilab host Hands-on Advanced Tutorial Sessions (HATS)\footnote{\url{http://lpc.fnal.gov/programs/schools-workshops/}} throughout the year to introduce and train participants in topics as diverse as the latest $b$-tagging algorithms, Git/Github, and even Machine Learning. These HATS provide face-to-face time with instructors and participants at Fermilab, but also allow remote collaborators to join in by video and complete the same online exercises. A similar approach is in use in the CMS Data Analysis Schools (CMSDAS)\footnote{\url{http://lpc.fnal.gov/programs/schools-workshops/cmsdas.shtml}}, a series of week-long workshops that now take place at multiple labs all over the world and are designed to ramp up new collaborators in CMS-specific analysis tools while providing some discussion of the physics as well. Anecdotally, these are viewed as a great success by the CMS community in preparing new collaborators and might serve as a model for future efforts in ML training.


Over the past decade, massive open online courses (MOOCs) have been developed by universities and private organizations. They have been well received by industry and academia and are maintained by the outside community. In addition, they provide a lot of flexibility in terms of cost and time constraints; they are typically free and open for enrollment at any time of the year. Since the material can be accessed at any time and revisited at any time, material can be completed at a pace that makes sense for a HEP that needs to learn ML in a piecemeal way.

There are a growing number of viable options of MOOCs teaching ML. Since there are several options, there is a variety with respect to the depth of the material and specific tools taught. Exploring these options allows us to choose which is the right offering for the knowledge needed to work on a specific HEP experiment. We can pick and choose modules to tailor an appropriate road map of skills to learn.

For example, at the time of this writing, Coursera\footnote{\url{https://www.coursera.org/learn/machine-learning}} and Udacity\footnote{\url{https://www.udacity.com/course/intro-to-machine-learning--ud120}} both provide great machine learning massive open online courses (MOOC) at no cost. These two courses both provide a great foundation for learning ML fundamentals. However, Coursera's approach emphasizes more theory (with more math background necessary) and uses MATLAB/Octave while Udacity's approach emphasizes practical using ML techniques in a practical sense using Python tooling.

In addition, Colfax also provides HOW (Hands On Workshop) series which is oriented towards HPC and parallel programming on multicore and manycore architectures. One of the key features is the provisioning of servers (Xeon and KNLs) for hands on development for student. More information can be found at - https://colfaxresearch.com/how-17-06/.

NEEDED: blog posts, podcasts, etc

\begin{itemize}
 \item Encourage global field summaries of recent applications of ML at large conferences and schools
 \item Use the existing forums like experiment specific training
 \item Include the CERN Knowledge transfer group type of activities $\to$ motivate tutors by providing them with more challenging problems, opportunities to learn something new How do you create incentives for experts to share knowledge?
\end{itemize}

It should be considered that some professors who act as graduate advisors might need to be encouraged to make sure their graduate students are properly trained. Sometimes, students are instead pushed to learn the bare minimum to get the work done, at the expense of a broader training/education curriculum which could actually yield improved results, but further down the line. One incentive would be to provide training programs which also count as course credit, perhaps towards an elective. This model is already in limited use with some online solutions\footnote{\url{https://www.edx.org/credit}}, but this is not universal. Discussions should be started with collaborators at higher education institutions to see what the roadblocks or opportunities would be for these training sessions to serve double duty.


\subsubsection{Link to the ML Community}
\begin{itemize}

 \item How to motivate the community to participate in developing programs? Can some of it come from the ML group \& leadership?
 \item see above
 \item How to deal with competitiveness in the field? Can‚Äôt force people to be interested in forming a community. How can we incentivize this? Building a vibrant, welcoming community may help. Link to Bridges.
\end{itemize}

\subsubsection{Tool Development}
Maybe this belongs in ‚ÄúExternal and Internal ML tools‚Äù
\begin{itemize}
 \item Open source implementations to be developed by the community
 \item Development of packages to transfer implementations across frameworks
\end{itemize}

\subsubsection{HEP-ML Continuing Communication}
%\begin{itemize}
Efforts to maintain communication between groups engaged in ML research and development will be initiated and maintained such as:
\begin{itemize}
 \item Meetings and workshops open to anyone that target leaders in the field to keep them current will be held.
 \item A regular newsletter that describes recent news, meetings, tools, and tutorials will be periodically distributed.
 \item Journal club meetings in which anyone can participate will be held. One goal of such meetings will be for experts to mentor beginners to enhance their knowledge and experience.
       \begin{itemize}
        \item This is a great way to discuss how to move from theory (reading the paper) to practice (discussing it).
        \item Someone is chosen to present the paper and draft a brief write-up which is archived and available for people to read at a later time.
       \end{itemize}
\end{itemize}

Training networks: two ML-focused ph-d training networks exist, can trained students train
others
TO-DO: roadmap, long term goals to meet, assessment strategies, how to involve
pre-existing training networks
One of the points that we thought were important to take into account is that the community to
educate will be a substantial extension of the users community, which was primarily taken into
account previously. If we want the results of modern machine learning (deep learning or else) to
be, both used and accepted, given the fact they are quite new and unknown, by the rest of the
experiment, the community at large needs to be educated.
Given that, the practitioners (that mean, us, and the future ML users) will have to be able to
justify their choices in front of community, use of pedagogy, and for this resources should also
be dedicated. The community training needs some deep understanding of ‚Äúproof-of-concept‚Äù
that the nice fancy black-box tool actually provides usable results.
Put emphasis on statistics and uncertainty control, maybe develop a dedicated team / task force
to assess it.
\end{comment}
